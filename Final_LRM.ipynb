{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58391a2b-c608-41fa-84eb-35f95147f638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/8b/c640e4a243b59fc75e566ff3509ae55fb6cd4535643494be834c7d69c25d/statsmodels-0.14.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8MB 5.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (24.1)\n",
      "Collecting patsy>=0.5.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/f3/1d311a09c34f14f5973bb0bb0dc3a6e007e1eda90b5492d082689936ca51/patsy-0.5.6-py2.py3-none-any.whl (233kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 89.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.22.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.26.4)\n",
      "Collecting scipy!=1.9.2,>=1.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6MB 84.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Installing collected packages: patsy, scipy, statsmodels\n",
      "Successfully installed patsy-0.5.6 scipy-1.13.1 statsmodels-0.14.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525dc345-b7e8-4dc8-bf70-17b748cd44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/9d/d332ec76e2cc442fce98bc43a44e69d3c281e6b4ede6b6db2616dc6fbec6/scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4MB 767kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting joblib>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 90.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d546a720-5aa5-4492-8181-a02f0f0cb03f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Let's convert 'ORDER_MONTH' to datetime and proceed with forecasting for each 'PRODUCT_ID'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"AGG_QTY_MASTER_DATA\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "df['ORDER_MONTH'] = pd.to_datetime(df['ORDER_MONTH'])\n",
    "\n",
    "#print(f\"{df['ORDER_MONTH']}\")\n",
    "\n",
    "# Sort the DataFrame by 'ORDER_MONTH' to maintain the time series order\n",
    "df = df.sort_values(by=['PRODUCT_ID', 'ORDER_MONTH'])\n",
    "\n",
    "# Function to create multiple lag features for ORDER_QTY\n",
    "def create_lags(df, target_column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df[f'Lag_{lag}'] = df[target_column].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Define a function that applies the prediction process for each product, including RMSE and R² calculation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_single_model(df, num_lags=6):\n",
    "    # Create lag features for ORDER_QTY\n",
    "    df = create_lags(df, 'ORDER_QTY', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    df['ORDER_MONTH_ORDINAL'] = df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # One-hot encode 'PART_CODE' and 'CATEGORY'\n",
    "   # part_code_encoded = pd.get_dummies(df['PART_CODE'], prefix='PART_CODE')\n",
    "    #category_encoded = pd.get_dummies(df['CATEGORY'], prefix='CATEGORY')\n",
    "\n",
    "    # Add the encoded columns to the df\n",
    "   # df = pd.concat([df, part_code_encoded, category_encoded], axis=1)\n",
    "\n",
    "    # Define the features (Lag_1, Lag_2, ..., Lag_n, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, encoded columns)\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    #part_code_columns = list(part_code_encoded.columns)\n",
    "    #category_columns = list(category_encoded.columns)\n",
    "    feature_columns = lag_columns + ['UNIT_PRICE', 'LEAD_TIME_IN_WEEKS', 'ORDER_MONTH_ORDINAL']\n",
    "\n",
    "    # Define X (features) and y (target)\n",
    "    X = df[feature_columns]\n",
    "    y = df['ORDER_QTY']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    from fosforml import register_model\n",
    "    \n",
    "    register_model(\n",
    "    model_obj=model,\n",
    "    session=my_session,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test =y_test,\n",
    "    y_pred=y_pred,\n",
    "    source=\"Notebook\",\n",
    "    dataset_name=\"AGG_QTY_MASTER_DATA\",\n",
    "    dataset_source=\"Snowflake\",\n",
    "    name=\"final_forecast_df\",\n",
    "    description=\"This is model for order forecast\",\n",
    "    flavour=\"sklearn\",\n",
    "    model_type=\"Regression\",\n",
    "    conda_dependencies=[\"scikit-learn==1.3.2\"]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return model, rmse, r2, X_test, y_test, df, feature_columns\n",
    "\n",
    "def forecast_for_each_product(model, product_df, df, feature_columns, num_lags=6, forecast_periods=25):\n",
    "    # Use the same lag columns and part code/category one-hot encoding\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "#    part_code_columns = [col for col in df.columns if col.startswith('PART_CODE')]\n",
    "#    category_columns = [col for col in df.columns if col.startswith('CATEGORY')]\n",
    "\n",
    "    # Create forecast for a specific product\n",
    "    # Create lag features for ORDER_QTY\n",
    "    product_df = create_lags(product_df, 'ORDER_QTY', num_lags)\n",
    "    \n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    product_df = product_df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    product_df['ORDER_MONTH_ORDINAL'] = product_df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # Add the PART_CODE and CATEGORY encodings directly (from df, since they already exist)\n",
    "    #product_df = pd.concat([product_df, df[part_code_columns + category_columns]], axis=1)\n",
    "\n",
    "    # Define X (features) for this product\n",
    "    X_product = product_df[feature_columns]\n",
    "\n",
    "    # Forecast for the next 25 months\n",
    "    future_months = pd.date_range(product_df['ORDER_MONTH'].max(), periods=forecast_periods, freq='MS')\n",
    "\n",
    "    # Initialize the last known lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, and ORDER_MONTH_ORDINAL\n",
    "    last_lags = list(product_df[lag_columns].iloc[-1])\n",
    "    last_unit_price = product_df['UNIT_PRICE'].iloc[-1]\n",
    "    last_lead_time = product_df['LEAD_TIME_IN_WEEKS'].iloc[-1]\n",
    "    last_order_month_ordinal = product_df['ORDER_MONTH_ORDINAL'].iloc[-1]\n",
    "    #last_part_code_encoded = product_df[part_code_columns].iloc[-1].values  # Part code one-hot encoding\n",
    "    #last_category_encoded = product_df[category_columns].iloc[-1].values  # Category one-hot encoding\n",
    "\n",
    "    # Create an empty list to store predictions\n",
    "    future_preds = []\n",
    "\n",
    "    for i in range(forecast_periods):\n",
    "        # Increment the ORDER_MONTH_ORDINAL for the next future month\n",
    "        last_order_month_ordinal += 30  # Assuming average month is ~30 days\n",
    "\n",
    "        # Prepare input features for the next prediction, including lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, PART_CODE_encoded, CATEGORY_encoded\n",
    "        future_X = np.array([last_lags + [last_unit_price, last_lead_time, last_order_month_ordinal] ])\n",
    "\n",
    "        # Predict the next ORDER_QTY\n",
    "        future_pred = model.predict(future_X)[0]\n",
    "\n",
    "        # Append the prediction to the list\n",
    "        future_preds.append(future_pred)\n",
    "\n",
    "        # Update lag values for the next iteration\n",
    "        last_lags = [future_pred] + last_lags[:-1]  # Shift the lags with the new prediction\n",
    "\n",
    "    # Format future_months as 'YYYY-MMM' (e.g., '2024-Aug')\n",
    "    future_months_formatted = future_months.strftime('%Y-%b')\n",
    "\n",
    "    # Create a DataFrame for this product's future ORDER_QTY predictions\n",
    "    future_forecast_df = pd.DataFrame({\n",
    "        'ORDER_MONTH': future_months_formatted,\n",
    "        'Predicted_ORDER_QTY': future_preds,\n",
    "        'PRODUCT_ID': product_df['PRODUCT_ID'].iloc[0],  # Add the PRODUCT_ID to each row\n",
    "    })\n",
    "\n",
    "    return future_forecast_df\n",
    "\n",
    "# Example usage:\n",
    "# Train the model once on the entire dataset\n",
    "model, rmse, r2, X_test, y_test, df, feature_columns = train_single_model(df)\n",
    "\n",
    "#print(f\"{rmse},{r2}\")\n",
    "\n",
    "# Loop through each product and forecast its future ORDER_QTY\n",
    "all_forecasts = []\n",
    "\n",
    "for product_id, product_df in df.groupby('PRODUCT_ID'):\n",
    "    forecast_df = forecast_for_each_product(model, product_df, df, feature_columns)\n",
    "    all_forecasts.append(forecast_df)\n",
    "\n",
    "# Combine all forecasts into one DataFrame\n",
    "final_forecast_df = pd.concat(all_forecasts)\n",
    "final_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05eb8449-36a2-4781-892b-3e4a312eac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml import register_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525557aa-d1aa-4f4f-af7b-c22f92772049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "|\"ORDER_MONTH\"  |\"Predicted_ORDER_QTY\"  |\"PRODUCT_ID\"  |\n",
      "--------------------------------------------------------\n",
      "|2024-Aug       |113131.03332486156     |Product_001   |\n",
      "|2024-Sep       |112961.39458722378     |Product_001   |\n",
      "|2024-Oct       |112791.08491499552     |Product_001   |\n",
      "|2024-Nov       |112620.10535611867     |Product_001   |\n",
      "|2024-Dec       |112448.45661032417     |Product_001   |\n",
      "|2025-Jan       |112276.13949474705     |Product_001   |\n",
      "|2025-Feb       |112103.36207469618     |Product_001   |\n",
      "|2025-Mar       |111930.12582129621     |Product_001   |\n",
      "|2025-Apr       |111756.43220199621     |Product_001   |\n",
      "|2025-May       |111582.2826807689      |Product_001   |\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_df = my_session.createDataFrame(final_forecast_df)\n",
    "sf_df.write.mode(\"overwrite\").save_as_table(\"ORDER_FORECAST_NEW\")\n",
    "my_session.table(\"ORDER_FORECAST_NEW\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a7081a-8748-4f87-ba02-d2968303193f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m register_model(\n\u001b[1;32m      2\u001b[0m     model_obj\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     session\u001b[38;5;241m=\u001b[39mmy_session,\n\u001b[0;32m----> 4\u001b[0m     X_train\u001b[38;5;241m=\u001b[39m\u001b[43mX_train\u001b[49m,\n\u001b[1;32m      5\u001b[0m     X_test\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[1;32m      6\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m      7\u001b[0m     y_test \u001b[38;5;241m=\u001b[39my_test,\n\u001b[1;32m      8\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m      9\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAGG_QTY_MASTER_DATA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     dataset_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnowflake\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_forecast_df\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is model for order forecast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     flavour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     conda_dependencies\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn==1.3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "register_model(\n",
    "    model_obj=model,\n",
    "    session=my_session,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test =y_test,\n",
    "    y_pred=y_pred,\n",
    "    source=\"Notebook\",\n",
    "    dataset_name=\"AGG_QTY_MASTER_DATA\",\n",
    "    dataset_source=\"Snowflake\",\n",
    "    name=\"final_forecast_df\",\n",
    "    description=\"This is model for order forecast\",\n",
    "    flavour=\"sklearn\",\n",
    "    model_type=\"Regression\",\n",
    "    conda_dependencies=[\"scikit-learn==1.3.2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13adb2-92f3-4cd2-b3a4-3f143848881b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
