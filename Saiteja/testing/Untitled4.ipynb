{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baea387d-c1c4-4032-8f5b-ab028a597d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019-01-01\n",
      "1       2019-02-01\n",
      "2       2019-03-01\n",
      "3       2019-04-01\n",
      "4       2019-05-01\n",
      "           ...    \n",
      "38755   2024-04-01\n",
      "38756   2024-05-01\n",
      "38757   2024-06-01\n",
      "38758   2024-07-01\n",
      "38759   2024-08-01\n",
      "Name: ORDER_MONTH, Length: 38760, dtype: datetime64[ns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m all_forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product_id, product_df \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 160\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_for_each_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     all_forecasts\u001b[38;5;241m.\u001b[39mappend(forecast_df)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Combine all forecasts into one DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m, in \u001b[0;36mforecast_for_each_product\u001b[0;34m(model, product_df, df, feature_columns, num_lags, forecast_periods)\u001b[0m\n\u001b[1;32m    129\u001b[0m future_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([last_lags \u001b[38;5;241m+\u001b[39m [last_unit_price, last_lead_time, last_order_month_ordinal] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(last_part_code_encoded) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(last_category_encoded)])\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Predict the next ORDER_QTY\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m future_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_X\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Append the prediction to the list\u001b[39;00m\n\u001b[1;32m    135\u001b[0m future_preds\u001b[38;5;241m.\u001b[39mappend(future_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    367\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:946\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead."
     ]
    }
   ],
   "source": [
    "# Let's convert 'ORDER_MONTH' to datetime and proceed with forecasting for each 'PRODUCT_ID'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"AGG_QTY_MASTER_DATA\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "df['ORDER_MONTH'] = pd.to_datetime(df['ORDER_MONTH'])\n",
    "\n",
    "print(f\"{df['ORDER_MONTH']}\")\n",
    "\n",
    "# Sort the DataFrame by 'ORDER_MONTH' to maintain the time series order\n",
    "df = df.sort_values(by=['PRODUCT_ID', 'ORDER_MONTH'])\n",
    "\n",
    "# Function to create multiple lag features for ORDER_QTY\n",
    "def create_lags(df, target_column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df[f'Lag_{lag}'] = df[target_column].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Define a function that applies the prediction process for each product, including RMSE and R² calculation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_single_model(df, num_lags=6):\n",
    "    # Create lag features for ORDER_QTY\n",
    "    df = create_lags(df, 'ORDER_QTY', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    df['ORDER_MONTH_ORDINAL'] = df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # One-hot encode 'PART_CODE' and 'CATEGORY'\n",
    "    part_code_encoded = pd.get_dummies(df['PART_CODE'], prefix='PART_CODE')\n",
    "    category_encoded = pd.get_dummies(df['CATEGORY'], prefix='CATEGORY')\n",
    "\n",
    "    # Add the encoded columns to the df\n",
    "    df = pd.concat([df, part_code_encoded, category_encoded], axis=1)\n",
    "\n",
    "    # Define the features (Lag_1, Lag_2, ..., Lag_n, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, encoded columns)\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    part_code_columns = list(part_code_encoded.columns)\n",
    "    category_columns = list(category_encoded.columns)\n",
    "    feature_columns = lag_columns + ['UNIT_PRICE', 'LEAD_TIME_IN_WEEKS', 'ORDER_MONTH_ORDINAL'] + part_code_columns + category_columns\n",
    "\n",
    "    # Define X (features) and y (target)\n",
    "    X = df[feature_columns]\n",
    "    y = df['ORDER_QTY']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return model, rmse, r2, X_test, y_test, df, feature_columns\n",
    "\n",
    "def forecast_for_each_product(model, product_df, df, feature_columns, num_lags=6, forecast_periods=25):\n",
    "    # Use the same lag columns and part code/category one-hot encoding\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    part_code_columns = [col for col in df.columns if col.startswith('PART_CODE')]\n",
    "    category_columns = [col for col in df.columns if col.startswith('CATEGORY')]\n",
    "\n",
    "    # Create forecast for a specific product\n",
    "    # Create lag features for ORDER_QTY\n",
    "    product_df = create_lags(product_df, 'ORDER_QTY', num_lags)\n",
    "    \n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    product_df = product_df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    product_df['ORDER_MONTH_ORDINAL'] = product_df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # Add the PART_CODE and CATEGORY encodings directly (from df, since they already exist)\n",
    "    product_df = pd.concat([product_df, df[part_code_columns + category_columns]], axis=1)\n",
    "\n",
    "    # Define X (features) for this product\n",
    "    X_product = product_df[feature_columns]\n",
    "\n",
    "    # Forecast for the next 25 months\n",
    "    future_months = pd.date_range(product_df['ORDER_MONTH'].max(), periods=forecast_periods, freq='MS')\n",
    "\n",
    "    # Initialize the last known lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, and ORDER_MONTH_ORDINAL\n",
    "    last_lags = list(product_df[lag_columns].iloc[-1])\n",
    "    last_unit_price = product_df['UNIT_PRICE'].iloc[-1]\n",
    "    last_lead_time = product_df['LEAD_TIME_IN_WEEKS'].iloc[-1]\n",
    "    last_order_month_ordinal = product_df['ORDER_MONTH_ORDINAL'].iloc[-1]\n",
    "    last_part_code_encoded = product_df[part_code_columns].iloc[-1].values  # Part code one-hot encoding\n",
    "    last_category_encoded = product_df[category_columns].iloc[-1].values  # Category one-hot encoding\n",
    "\n",
    "    # Create an empty list to store predictions\n",
    "    future_preds = []\n",
    "\n",
    "    for i in range(forecast_periods):\n",
    "        # Increment the ORDER_MONTH_ORDINAL for the next future month\n",
    "        last_order_month_ordinal += 30  # Assuming average month is ~30 days\n",
    "\n",
    "        # Prepare input features for the next prediction, including lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, PART_CODE_encoded, CATEGORY_encoded\n",
    "        future_X = np.array([last_lags + [last_unit_price, last_lead_time, last_order_month_ordinal] + list(last_part_code_encoded) + list(last_category_encoded)])\n",
    "\n",
    "        # Predict the next ORDER_QTY\n",
    "        future_pred = model.predict(future_X)[0]\n",
    "\n",
    "        # Append the prediction to the list\n",
    "        future_preds.append(future_pred)\n",
    "\n",
    "        # Update lag values for the next iteration\n",
    "        last_lags = [future_pred] + last_lags[:-1]  # Shift the lags with the new prediction\n",
    "\n",
    "    # Format future_months as 'YYYY-MMM' (e.g., '2024-Aug')\n",
    "    future_months_formatted = future_months.strftime('%Y-%b')\n",
    "\n",
    "    # Create a DataFrame for this product's future ORDER_QTY predictions\n",
    "    future_forecast_df = pd.DataFrame({\n",
    "        'ORDER_MONTH': future_months_formatted,\n",
    "        'Predicted_ORDER_QTY': future_preds,\n",
    "        'PRODUCT_ID': product_df['PRODUCT_ID'].iloc[0],  # Add the PRODUCT_ID to each row\n",
    "    })\n",
    "\n",
    "    return future_forecast_df\n",
    "\n",
    "# Example usage:\n",
    "# Train the model once on the entire dataset\n",
    "model, rmse, r2, X_test, y_test, df, feature_columns = train_single_model(df)\n",
    "\n",
    "# Loop through each product and forecast its future ORDER_QTY\n",
    "all_forecasts = []\n",
    "\n",
    "for product_id, product_df in df.groupby('PRODUCT_ID'):\n",
    "    forecast_df = forecast_for_each_product(model, product_df, df, feature_columns)\n",
    "    all_forecasts.append(forecast_df)\n",
    "\n",
    "# Combine all forecasts into one DataFrame\n",
    "final_forecast_df = pd.concat(all_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29382923-4a9c-415e-bd00-9f26229e2afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
