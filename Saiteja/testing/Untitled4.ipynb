{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cd2373-c20d-4b7d-a1ff-d940106a975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019-01-01\n",
      "1       2019-02-01\n",
      "2       2019-03-01\n",
      "3       2019-04-01\n",
      "4       2019-05-01\n",
      "           ...    \n",
      "38755   2024-04-01\n",
      "38756   2024-05-01\n",
      "38757   2024-06-01\n",
      "38758   2024-07-01\n",
      "38759   2024-08-01\n",
      "Name: ORDER_MONTH, Length: 38760, dtype: datetime64[ns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The column label 'PART_CODE' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6098/2844415870.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# Let's convert 'ORDER_MONTH' to datetime and proceed with forecasting for each 'PRODUCT_ID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6098/2844415870.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, product_df, df, feature_columns, num_lags, forecast_periods)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Convert 'ORDER_MONTH' to an ordinal number to use as a feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mproduct_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORDER_MONTH_ORDINAL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORDER_MONTH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoordinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Add the encoded 'PART_CODE' columns from the main df to the product_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mproduct_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_code_columns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PART_CODE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PART_CODE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# Define X (features) for this product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mX_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10801\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10802\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10803\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10805\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10806\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10807\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10808\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m                 \u001b[0mmulti_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0mlabel_axis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"column\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"index\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1925\u001b[0m                 \u001b[0;34mf\"The {label_axis_name} label '{key}' is not unique.{multi_message}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             )\n\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The column label 'PART_CODE' is not unique."
     ]
    }
   ],
   "source": [
    "# Let's convert 'ORDER_MONTH' to datetime and proceed with forecasting for each 'PRODUCT_ID'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"AGG_QTY_MASTER_DATA\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "df['ORDER_MONTH'] = pd.to_datetime(df['ORDER_MONTH'])\n",
    "\n",
    "print(f\"{df['ORDER_MONTH']}\")\n",
    "\n",
    "# Sort the DataFrame by 'ORDER_MONTH' to maintain the time series order\n",
    "df = df.sort_values(by=['PRODUCT_ID', 'ORDER_MONTH'])\n",
    "\n",
    "# Function to create multiple lag features for ORDER_QTY\n",
    "def create_lags(df, target_column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df[f'Lag_{lag}'] = df[target_column].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Define a function that applies the prediction process for each product, including RMSE and R² calculation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def train_single_model(df, num_lags=6):\n",
    "    # Create lag features for ORDER_QTY\n",
    "    df = create_lags(df, 'ORDER_QTY', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    df['ORDER_MONTH_ORDINAL'] = df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # One-hot encode 'PART_CODE'\n",
    "    part_code_encoded = pd.get_dummies(df['PART_CODE'], prefix='PART_CODE')\n",
    "\n",
    "    # Add the encoded 'PART_CODE' columns to the df\n",
    "    df = pd.concat([df, part_code_encoded], axis=1)\n",
    "\n",
    "    # Define the features (Lag_1, Lag_2, ..., Lag_n, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, PART_CODE_encoded_columns)\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    part_code_columns = list(part_code_encoded.columns)\n",
    "    feature_columns = lag_columns + ['UNIT_PRICE', 'LEAD_TIME_IN_WEEKS', 'ORDER_MONTH_ORDINAL'] + part_code_columns\n",
    "\n",
    "    # Define X (features) and y (target)\n",
    "    X = df[feature_columns]\n",
    "    y = df['ORDER_QTY']\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return model, rmse, r2, X_test, y_test, df, feature_columns\n",
    "\n",
    "def forecast_for_each_product(model, product_df, df, feature_columns, num_lags=6, forecast_periods=25):\n",
    "    # Use the same lag columns and part code one-hot encoding\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    part_code_columns = [col for col in df.columns if col.startswith('PART_CODE')]\n",
    "\n",
    "    # Create forecast for a specific product\n",
    "    # Create lag features for ORDER_QTY\n",
    "    product_df = create_lags(product_df, 'ORDER_QTY', num_lags)\n",
    "    \n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    product_df = product_df.dropna()\n",
    "\n",
    "    # Convert 'ORDER_MONTH' to an ordinal number to use as a feature\n",
    "    product_df['ORDER_MONTH_ORDINAL'] = product_df['ORDER_MONTH'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # Add the encoded 'PART_CODE' columns from the main df to the product_df\n",
    "    product_df = product_df.merge(df[part_code_columns + ['PART_CODE']], on='PART_CODE', how='left')\n",
    "\n",
    "    # Define X (features) for this product\n",
    "    X_product = product_df[feature_columns]\n",
    "\n",
    "    # Forecast for the next 25 months\n",
    "    future_months = pd.date_range(product_df['ORDER_MONTH'].max(), periods=forecast_periods, freq='MS')\n",
    "\n",
    "    # Initialize the last known lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, and ORDER_MONTH_ORDINAL\n",
    "    last_lags = list(product_df[lag_columns].iloc[-1])\n",
    "    last_unit_price = product_df['UNIT_PRICE'].iloc[-1]\n",
    "    last_lead_time = product_df['LEAD_TIME_IN_WEEKS'].iloc[-1]\n",
    "    last_order_month_ordinal = product_df['ORDER_MONTH_ORDINAL'].iloc[-1]\n",
    "    last_part_code_encoded = product_df[part_code_columns].iloc[-1].values  # Part code one-hot encoding\n",
    "\n",
    "    # Create an empty list to store predictions\n",
    "    future_preds = []\n",
    "\n",
    "    for i in range(forecast_periods):\n",
    "        # Increment the ORDER_MONTH_ORDINAL for the next future month\n",
    "        last_order_month_ordinal += 30  # Assuming average month is ~30 days\n",
    "\n",
    "        # Prepare input features for the next prediction, including lag values, UNIT_PRICE, LEAD_TIME_IN_WEEKS, ORDER_MONTH_ORDINAL, and PART_CODE_encoded columns\n",
    "        future_X = np.array([last_lags + [last_unit_price, last_lead_time, last_order_month_ordinal] + list(last_part_code_encoded)])\n",
    "\n",
    "        # Predict the next ORDER_QTY\n",
    "        future_pred = model.predict(future_X)[0]\n",
    "\n",
    "        # Append the prediction to the list\n",
    "        future_preds.append(future_pred)\n",
    "\n",
    "        # Update lag values for the next iteration\n",
    "        last_lags = [future_pred] + last_lags[:-1]  # Shift the lags with the new prediction\n",
    "\n",
    "    # Format future_months as 'YYYY-MMM' (e.g., '2024-Aug')\n",
    "    future_months_formatted = future_months.strftime('%Y-%b')\n",
    "\n",
    "    # Create a DataFrame for this product's future ORDER_QTY predictions\n",
    "    future_forecast_df = pd.DataFrame({\n",
    "        'ORDER_MONTH': future_months_formatted,\n",
    "        'Predicted_ORDER_QTY': future_preds,\n",
    "        'PRODUCT_ID': product_df['PRODUCT_ID'].iloc[0],  # Add the PRODUCT_ID to each row\n",
    "    })\n",
    "\n",
    "    return future_forecast_df\n",
    "\n",
    "# Example usage:\n",
    "# Train the model once on the entire dataset\n",
    "model, rmse, r2, X_test, y_test, df, feature_columns = train_single_model(df)\n",
    "\n",
    "# Loop through each product and forecast its future ORDER_QTY\n",
    "all_forecasts = []\n",
    "\n",
    "for product_id, product_df in df.groupby('PRODUCT_ID'):\n",
    "    forecast_df = forecast_for_each_product(model, product_df, df, feature_columns)\n",
    "    all_forecasts.append(forecast_df)\n",
    "\n",
    "# Combine all forecasts into one DataFrame\n",
    "final_forecast_df = pd.concat(all_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d015ed-5f41-49c4-ac1c-78ecae0a38c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
