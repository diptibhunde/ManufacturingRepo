{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec1c9f0-11c3-4481-8d03-be4524ea5a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.9/site-packages (0.14.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08a9cdd-7f79-4ffc-bd5a-1385af2089e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/9d/d332ec76e2cc442fce98bc43a44e69d3c281e6b4ede6b6db2616dc6fbec6/scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4MB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 85.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3059fd2b-0b65-4fd1-8328-b9966333f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f50f02a-c096-40e8-a9a3-f46e675f5a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming 'df' is the DataFrame that contains your data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('your_data.csv')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_manager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowflakesession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_session\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is the DataFrame that contains your data\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"MASTER_DATA\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()\n",
    "\n",
    "\n",
    "# Convert 'ORDER_DATE' to datetime\n",
    "df['ORDER_DATE'] = pd.to_datetime(df['ORDER_DATE'])\n",
    "\n",
    "# Sort data by 'ORDER_DATE' to maintain time series order\n",
    "df = df.sort_values(by='ORDER_DATE')\n",
    "\n",
    "# Function to create multiple lag features for ORDER_QTY\n",
    "def create_lags(df, target_column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df[f'Lag_{lag}'] = df[target_column].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Define a function that applies the prediction process for each product\n",
    "def forecast_for_product(product_df, num_lags=6, forecast_periods=25):\n",
    "    # Create lag features for ORDER_QTY\n",
    "    product_df = create_lags(product_df, 'ORDER_QTY', num_lags)\n",
    "    \n",
    "    # Drop rows with NaN values (due to shifting from lag features)\n",
    "    product_df = product_df.dropna()\n",
    "    \n",
    "    # Define the features (Lag_1, Lag_2, ..., Lag_n, UNIT_PRICE, LEAD_TIME_IN_WEEKS) and target (ORDER_QTY)\n",
    "    lag_columns = [f'Lag_{lag}' for lag in range(1, num_lags + 1)]\n",
    "    feature_columns = lag_columns + ['UNIT_PRICE', 'LEAD_TIME_IN_WEEKS']\n",
    "    \n",
    "    # Define X (features) and y (target)\n",
    "    X = product_df[feature_columns]\n",
    "    y = product_df['ORDER_QTY']\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Forecast for the next 25 months\n",
    "    # Create a new DataFrame for future dates\n",
    "    future_dates = pd.date_range(product_df['ORDER_DATE'].max(), periods=forecast_periods, freq='M')\n",
    "    \n",
    "    # Initialize the last known lag values, UNIT_PRICE, and LEAD_TIME_IN_WEEKS\n",
    "    last_lags = list(product_df[lag_columns].iloc[-1])\n",
    "    last_unit_price = product_df['UNIT_PRICE'].iloc[-1]\n",
    "    last_lead_time = product_df['LEAD_TIME_IN_WEEKS'].iloc[-1]\n",
    "    \n",
    "    # Create an empty list to store predictions\n",
    "    future_preds = []\n",
    "    \n",
    "    for i in range(forecast_periods):\n",
    "        # Prepare input features for the next prediction, including lag values, UNIT_PRICE, and LEAD_TIME_IN_WEEKS\n",
    "        future_X = np.array([last_lags + [last_unit_price, last_lead_time]])\n",
    "        \n",
    "        # Predict the next ORDER_QTY\n",
    "        future_pred = model.predict(future_X)[0]\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        future_preds.append(future_pred)\n",
    "        \n",
    "        # Update lag values for the next iteration\n",
    "        last_lags = [future_pred] + last_lags[:-1]  # Shift the lags with the new prediction\n",
    "\n",
    "    # Create a DataFrame for this product's future ORDER_QTY predictions\n",
    "    future_forecast_df = pd.DataFrame({\n",
    "        'ORDER_DATE': future_dates,\n",
    "        'Predicted_ORDER_QTY': future_preds,\n",
    "        'PRODUCT_ID': product_df['PRODUCT_ID'].iloc[0]  # Add the PRODUCT_ID to each row\n",
    "    })\n",
    "    \n",
    "    return future_forecast_df\n",
    "\n",
    "# Initialize an empty DataFrame to store all product forecasts\n",
    "all_products_forecast_df = pd.DataFrame()\n",
    "\n",
    "# Loop over each product group by 'PRODUCT_ID'\n",
    "for product_id, product_df in df.groupby('PRODUCT_ID'):\n",
    "    # Apply the forecast function for each product\n",
    "    product_forecast_df = forecast_for_product(product_df)\n",
    "    \n",
    "    # Append the forecast for this product to the overall forecast DataFrame\n",
    "    all_products_forecast_df = pd.concat([all_products_forecast_df, product_forecast_df], ignore_index=True)\n",
    "\n",
    "# Rename the columns\n",
    "all_products_forecast_df.rename(columns={'Predicted_ORDER_QTY': 'ORDER_QTY'}, inplace=True)\n",
    "\n",
    "# Display the combined forecast DataFrame for all products\n",
    "print(all_products_forecast_df)\n",
    "\n",
    "# Optionally, save the resulting DataFrame to a CSV file\n",
    "# all_products_forecast_df.to_csv('all_products_order_qty_forecast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85b0b7-baac-4902-b860-bfaa199ff2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
